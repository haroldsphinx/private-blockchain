
## Notes.txt

## Approach
- The challenge mentioned ArgoCD, Helm, k8s tooling so I went with a Kurtosis + minikube setup
- Kurtosis handles the ethereum network orchestration (geth + lighthouse), I point it at k8s and it does the heavy lifting
- Two deployment routes: local minikube via setup.sh, or a Terraform-provisioned EC2 that bootstraps the same minikube stack via cloud-init
- Both routes use the same kurtosis/network_params.yaml, only difference is where minikube runs

## Kurtosis
- Used ethpandaops/ethereum-package which is what most ethereum testnets use
- Ran into fulu fork issues with small validator counts, had to set fulu_fork_epoch to uint64 max to disable it
- Kurtosis on k8s backend requires `kurtosis gateway` running to access services from the host
- Port discovery is annoying, kurtosis assigns random ports so I parse `kurtosis enclave inspect` output

## Terraform
- Reused existing compute modules I had from previous work
- Cloud-init installs minikube, kubectl, helm, kurtosis, ArgoCD, then deploys the network
- Instance needs t3.xlarge (4 vCPU, 16GB RAM) to run minikube + blockchain + observability + ArgoCD
- Used socat to bridge kurtosis gateway (binds 127.0.0.1) to external interfaces

## ArgoCD
- Manages the observability stack (kube-prometheus-stack via Helm chart)
- There's also an ArgoCD app for the blockchain Job deployment, but setup.sh deploys via kurtosis directly since it's more reliable for initial setup
- ArgoCD values are tuned down for single-node minikube (low resource limits)

## Ingress
- Used minikube's built-in nginx ingress addon, no extra helm chart
- Routes: rpc.haroldsphinx.com, explorer.haroldsphinx.com, grafana.haroldsphinx.com, argocd.haroldsphinx.com
- On the VM, single kubectl port-forward of the ingress controller on 0.0.0.0:80 replaces all the per-service port-forwards
- Also kept a direct socat on :8545 for RPC since some tools expect that port

## Observability
- kube-prometheus-stack deployed via ArgoCD with custom scrape configs for kurtosis pods (kubernetes_sd_configs targeting kt-* namespaces)
- Alert rules: ELNodeDown, CLNodeDown, PeerCountLow, NoNewBlocks
- The observability/ directory has standalone docker-compose configs that were used during early development, kept for reference

## CI
- validate-network.yml: docker backend, installs kurtosis, deploys, runs assertoor validation
- validate-k8s.yml: minikube on the runner, kurtosis on k8s backend, same assertoor validation
- Both dump enclave logs as artifacts on failure

## If I had more time
- Set up proper DNS with Route53 for the haroldsphinx.com subdomains
- Add cert-manager for TLS
- Multi-node setup (separate EL/CL instances)
- Grafana dashboards with actual geth/lighthouse metrics panels instead of the basic overview
- Ansible for configuration management instead of cloud-init
